{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe5ba1d",
   "metadata": {},
   "source": [
    "# qcGEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6521ad7",
   "metadata": {},
   "source": [
    "### Load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb19554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2  \n",
    "%reload_ext autoreload\n",
    "\n",
    "import os\n",
    "os.chdir('/export/disk6/why/workbench/MERGE/GLI/0_qcGEM_Github_copy/run/')\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_add_pool, aggr\n",
    "import torch.nn.init as init  \n",
    "\n",
    "import models\n",
    "from dataset_pyg import qcGEM_Data, qcGEM_example\n",
    "from cal_loss import Loss_GNE\n",
    "\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "import molplotly\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd809e22",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Args of Representation Pre-train Model')\n",
    "\n",
    "parser.add_argument('--encoder_method', type=str, default='qcGEM_Encoder', metavar='N',\n",
    "                    help='Select the encoder model.')\n",
    "parser.add_argument('--decoder_method', type=str, default='qcGEM_Decoder', metavar='N',\n",
    "                    help='Select the decoder model.')\n",
    "\n",
    "args = parser.parse_args([\n",
    "                        '--encoder_method', 'qcGEM_Encoder',\n",
    "                        '--decoder_method', 'qcGEM_Decoder',\n",
    "                        ])\n",
    "\n",
    "args.encoder_layers = 16\n",
    "args.decoder_layers = 0\n",
    "args.heads = 8\n",
    "args.global_head_dim = 32\n",
    "args.node_head_dim = 32\n",
    "args.edge_head_dim = 32\n",
    "args.botnec_global_dim = 128\n",
    "args.botnec_node_dim = 128\n",
    "args.botnec_edge_dim = 128\n",
    "args.gm_interact_time = 4\n",
    "args.gm_layer_num = 3\n",
    "args.gm_cutoff = 8.0\n",
    "args.gm_output_dim = 12\n",
    "\n",
    "args.init = 'None'\n",
    "args.norm = 'layer'\n",
    "args.remove_self_loop = False\n",
    "args.global_mask_ratio = 1.0\n",
    "args.mask_ratio = 0.3\n",
    "args.replace_ratio = 0.3\n",
    "args.remask_ratio = 0.0\n",
    "\n",
    "args.device = 'cuda:7'\n",
    "args.pretrained = True\n",
    "args.pretrained_path = '../model/'\n",
    "args.pretrained_model = 'qcGEM_ckpt.pt'\n",
    "\n",
    "args.batch_size = 1\n",
    "args.root_path = '../data/'\n",
    "args.dataset = '20250101'\n",
    "args.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(args):\n",
    "    DataSet = qcGEM_example(root = args.root_path, dataset = args.dataset, split_mode = 'random', split_seed = 0)\n",
    "    data_loader_train = DataLoader(DataSet.train, batch_size=args.batch_size, shuffle = args.shuffle)\n",
    "    data_loader_valid = DataLoader(DataSet.val, batch_size=args.batch_size, shuffle = False)\n",
    "\n",
    "    return args, data_loader_train, data_loader_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a4b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "args, data_loader_train, data_loader_valid = build_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27b3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(args):\n",
    "\n",
    "    global_dim, xyz_dim, node_dim, edge_dim = [200, 512, 512], 3, 80, 53\n",
    "\n",
    "    model = models.qcGEM(input_global_dim= global_dim, global_head_dim = args.global_head_dim, botnec_global_dim = args.botnec_global_dim, \n",
    "                    input_node_dim = node_dim, node_head_dim = args.node_head_dim, BotNec_node_dim = args.botnec_node_dim, \n",
    "                    input_edge_dim = edge_dim, edge_head_dim = args.edge_head_dim, BotNec_edge_dim = args.botnec_edge_dim,\n",
    "                    heads = args.heads, \n",
    "                    device = args.device, act_fn = nn.GELU(), norm = args.norm,\n",
    "                    remove_self_loop = args.remove_self_loop,\n",
    "                    global_mask_ratio = args.global_mask_ratio, mask_ratio = args.mask_ratio, replace_ratio = args.replace_ratio, remask_ratio = args.remask_ratio,\n",
    "                    encoder_method = args.encoder_method, decoder_method = args.decoder_method,\n",
    "                    encoder_layers = args.encoder_layers, decoder_layers = args.decoder_layers,\n",
    "                    gm_cutoff = args.gm_cutoff, gm_output_dim = args.gm_output_dim, gm_interact_time = args.gm_interact_time, gm_layer_num = args.gm_layer_num)\n",
    "\n",
    "    num_1 = sum(p.numel() for p in model.parameters())\n",
    "    num_2 = sum(p.numel() for p in model.encoder.parameters())\n",
    "    num_3 = sum(p.numel() for p in model.decoder.parameters())\n",
    "    print(f' ==== The total num of parameters is {num_1}, Encoder is {num_2}, Decoder is {num_3}.')\n",
    "\n",
    "    if args.pretrained == True:\n",
    "        pre_trained_model_state = torch.load(f'{args.pretrained_path}/{args.pretrained_model}', map_location=torch.device(args.device))\n",
    "        model.load_state_dict(pre_trained_model_state['model_state_dict'], strict=True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return args, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206485b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==== The total num of parameters is 37002671, Encoder is 35958209, Decoder is 1044321.\n"
     ]
    }
   ],
   "source": [
    "args, model = build_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253cfdc",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09f54d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000781927']\n"
     ]
    }
   ],
   "source": [
    "for batch in data_loader_train:\n",
    "    batch = batch.to(args.device)\n",
    "    with torch.no_grad():\n",
    "        output = model(batch)\n",
    "    print(output[0]['CID_list'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7514422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec6f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG252",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
